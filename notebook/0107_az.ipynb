{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.typing import NDArray\n",
    "from scipy.optimize import minimize\n",
    "from typing import List, Tuple\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 価格を生成する関数\n",
    "def create_price(r_mean: float, r_std: float, M: int) -> NDArray[np.float_]:\n",
    "    # r_mean = (r_min + r_max) / 2\n",
    "    # r_std = (r_max - r_mean) / 2\n",
    "    # r_minとr_maxの間のランダムな0.1刻みの少数をM個生成\n",
    "    price = np.random.normal(r_mean, r_std, size=M)\n",
    "    # price = np.round(price, 1)\n",
    "\n",
    "    return price\n",
    "\n",
    "\n",
    "# alphaを作成する関数\n",
    "def alpha_star(M: int) -> NDArray[np.float_]:\n",
    "    alpha_star = np.random.uniform(M, 3 * M, size=M)\n",
    "    return alpha_star\n",
    "\n",
    "\n",
    "# betaを作成する関数\n",
    "def beta_star(M: int, M_prime: int) -> NDArray[np.float_]:\n",
    "    beta_star = np.zeros((M, M_prime))\n",
    "\n",
    "    for m in range(M):\n",
    "        for m_prime in range(M_prime):\n",
    "            if m == m_prime:\n",
    "                beta_star[m, m_prime] = np.random.uniform(-3 * M, -2 * M)\n",
    "            else:\n",
    "                beta_star[m, m_prime] = np.random.uniform(0, 3)\n",
    "\n",
    "    return beta_star\n",
    "\n",
    "\n",
    "def quantity_function(\n",
    "    price: NDArray[np.float_],\n",
    "    alpha: NDArray[np.float_],\n",
    "    beta: NDArray[np.float_],\n",
    "    delta: float = 0.1,  # ノイズレベルを指定（例として0.1を使用）\n",
    ") -> list[float]:\n",
    "    M = len(price)\n",
    "    quantity_list = []\n",
    "    q_m_no_noise = []\n",
    "\n",
    "    # ステップ1: ノイズなしのq_mを計算\n",
    "    for m in range(M):\n",
    "        sum_beta = 0\n",
    "        for m_prime in range(M):\n",
    "            sum_beta += beta[m][m_prime] * price[m_prime]\n",
    "        quantity = alpha[m] + sum_beta\n",
    "        q_m_no_noise.append(quantity)\n",
    "\n",
    "    # E[q_m^2]を計算\n",
    "    E_q_m_squared = np.mean(np.array(q_m_no_noise) ** 2)\n",
    "\n",
    "    # ステップ2: ノイズの標準偏差sigmaを計算\n",
    "    sigma = delta * np.sqrt(E_q_m_squared)\n",
    "\n",
    "    # ステップ3: ノイズを加えて最終的なq_mを計算\n",
    "    for m in range(M):\n",
    "        epsilon = np.random.normal(0, sigma)\n",
    "        quantity = q_m_no_noise[m] + epsilon\n",
    "        quantity_list.append(quantity)\n",
    "\n",
    "    return quantity_list\n",
    "\n",
    "\n",
    "def sales_function(\n",
    "    price: NDArray[np.float_], alpha: NDArray[np.float_], beta: NDArray[np.float_]\n",
    ") -> list[float]:\n",
    "    M = len(price)\n",
    "    sales_list = []\n",
    "\n",
    "    for m in range(M):\n",
    "        sum_beta = 0\n",
    "        for m_prime in range(M):\n",
    "            sum_beta += beta[m][m_prime] * price[m_prime]\n",
    "\n",
    "        quantity = alpha[m] + sum_beta\n",
    "        sales_list.append(quantity * price[m])\n",
    "\n",
    "    return sales_list\n",
    "\n",
    "\n",
    "def create_date(M, N, r_mean, r_std, delta=0.1):\n",
    "    alpha = alpha_star(M)\n",
    "    beta = beta_star(M, M)\n",
    "\n",
    "    price_list = []\n",
    "    quantity_list = []\n",
    "\n",
    "    for _ in range(N):\n",
    "        price = create_price(r_mean, r_std, M)\n",
    "        quantity = quantity_function(price, alpha, beta, delta)\n",
    "        price_list.append(price)\n",
    "        quantity_list.append(quantity)\n",
    "\n",
    "    X = np.array(price_list)\n",
    "    Y = np.array(quantity_list)\n",
    "\n",
    "    return alpha, beta, X, Y\n",
    "\n",
    "\n",
    "def create_bounds(M, r_min, r_max):\n",
    "    lb = np.full(M, r_min)\n",
    "    ub = np.full(M, r_max)\n",
    "\n",
    "    range_bounds = []\n",
    "    for i in range(M):\n",
    "        range_bounds.append(lb[i])\n",
    "\n",
    "    for i in range(M):\n",
    "        range_bounds.append(ub[i])\n",
    "\n",
    "    bounds = [(r_min, r_max) for _ in range(M)]\n",
    "\n",
    "    return lb, ub, bounds, range_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的関数を定義（最大化問題を最小化問題に変換）\n",
    "def sales_objective_function(prices, alpha, beta, M):\n",
    "    return -sum(\n",
    "        prices[m] * (alpha[m] + sum(beta[m][m_prime] * prices[m_prime] for m_prime in range(M)))\n",
    "        for m in range(M)\n",
    "    )\n",
    "\n",
    "\n",
    "def sales_optimize(\n",
    "    M: int,\n",
    "    alpha: np.ndarray,\n",
    "    beta: np.ndarray,\n",
    "    bounds: list[tuple[float, float]],\n",
    ") -> Tuple[float, np.ndarray]:\n",
    "    # 初期値として与えられたprices_listを使用\n",
    "    initial_prices = np.full(M, 0.6)\n",
    "\n",
    "    # 最適化を実行\n",
    "    result = minimize(\n",
    "        sales_objective_function,\n",
    "        initial_prices,\n",
    "        args=(alpha, beta, M),\n",
    "        bounds=bounds,\n",
    "        method=\"L-BFGS-B\",\n",
    "    )\n",
    "    # 最適な価格と目的関数の値を取得\n",
    "    optimal_prices = result.x\n",
    "    optimal_value = -result.fun  # 符号を反転して元の最大化問題の値に戻す\n",
    "    return optimal_value, optimal_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的関数を定義\n",
    "def predict_objective_function(\n",
    "    prices: NDArray[np.float_], intercepts: [float], coefs: [NDArray[np.float_]], M: int\n",
    ") -> float:\n",
    "    # 各変数の内容をデバッグ出力\n",
    "    # print(\"prices:\", prices)\n",
    "    # print(\"intercepts:\", intercepts)\n",
    "    # print(\"coefs:\", coefs)\n",
    "    # print(\"M:\", M)\n",
    "\n",
    "    return -sum(\n",
    "        prices[m]\n",
    "        * (intercepts[m] + sum(coefs[m][m_prime] * prices[m_prime] for m_prime in range(M)))\n",
    "        for m in range(M)\n",
    "    )\n",
    "\n",
    "\n",
    "# 予測と最適化を行う関数\n",
    "def predict_optimize(\n",
    "    M: int, X: NDArray[np.float_], Y: NDArray[np.float_], bounds: list[float]\n",
    ") -> tuple[float, NDArray[np.float_]]:\n",
    "    lr = MultiOutputRegressor(LinearRegression())\n",
    "    lr.fit(X, Y)\n",
    "    # 係数と切片を取得\n",
    "    coefs = [estimate.coef_ for estimate in lr.estimators_]\n",
    "    intercepts = [estimate.intercept_ for estimate in lr.estimators_]\n",
    "\n",
    "    # 初期値として与えられたprices_listを使用\n",
    "    initial_prices = np.full(M, 0.6)\n",
    "    # 最適化を実行\n",
    "    result = minimize(\n",
    "        predict_objective_function,\n",
    "        initial_prices,\n",
    "        args=(intercepts, coefs, M),\n",
    "        bounds=bounds,\n",
    "        method=\"L-BFGS-B\",\n",
    "    )\n",
    "    # 最適な価格と目的関数の値を取得\n",
    "    optimal_prices = result.x\n",
    "    optimal_value = -result.fun  # 符号を反転して元の最大化問題の値に戻す\n",
    "    return optimal_value, optimal_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVを行う関数\n",
    "def cross_validation(\n",
    "    tilda_coefs_list: list[NDArray[np.float_]],\n",
    "    tilda_intercepts_list: list[float],\n",
    "    hat_coefs_list: list[NDArray[np.float_]],\n",
    "    hat_intercepts_list: list[float],\n",
    "    M: int,\n",
    "    K: int,\n",
    "    bounds: list[float],\n",
    ") -> float:\n",
    "    optimal_sales_list = []\n",
    "\n",
    "    for i in range(K):\n",
    "        # 初期値として与えられたprices_listを使用\n",
    "        initial_prices = np.full(M, 0.6)\n",
    "\n",
    "        # 最適化を実行\n",
    "        result = minimize(\n",
    "            predict_objective_function,\n",
    "            initial_prices,\n",
    "            args=(tilda_intercepts_list[i], tilda_coefs_list[i], M),\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        # 最適な価格と目的関数の値を取得\n",
    "        optimal_prices = result.x\n",
    "\n",
    "        sales_hat = np.sum(\n",
    "            sales_function(optimal_prices, hat_intercepts_list[i], hat_coefs_list[i])\n",
    "        )\n",
    "\n",
    "        optimal_sales_list.append(sales_hat)\n",
    "\n",
    "    return np.mean(optimal_sales_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 変更後の cross_validation_bounds_zero_2\n",
    "def cross_validation_bounds_zero(\n",
    "    bounds: List[float],\n",
    "    tilda_coefs_list: List[NDArray[np.float_]],\n",
    "    tilda_intercepts_list: List[NDArray[np.float_]],\n",
    "    hat_coefs_list: List[NDArray[np.float_]],\n",
    "    hat_intercepts_list: List[NDArray[np.float_]],\n",
    "    M: int,\n",
    "    K: int,\n",
    ") -> float:\n",
    "    # bounds から (low, high) の形式に変換\n",
    "    bounds_list = []\n",
    "    for i in range(M):\n",
    "        if bounds[i] > bounds[i + M]:\n",
    "            return 0.0\n",
    "        else:\n",
    "            bounds_list.append((bounds[i], bounds[i + M]))\n",
    "\n",
    "    optimal_sales_list = []\n",
    "\n",
    "    for i in range(K):\n",
    "        # tildaパラメータで最適化（学習済み）\n",
    "        intercepts = tilda_intercepts_list[i]\n",
    "        coefs = tilda_coefs_list[i]\n",
    "\n",
    "        initial_prices = np.full(M, 0.6)\n",
    "        result = minimize(\n",
    "            predict_objective_function,\n",
    "            initial_prices,\n",
    "            args=(intercepts, coefs, M),\n",
    "            bounds=bounds_list,\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        optimal_prices = result.x\n",
    "\n",
    "        # 得られた最適価格でhatパラメータに基づく売上計算\n",
    "        alpha = hat_intercepts_list[i]\n",
    "        beta = hat_coefs_list[i]\n",
    "\n",
    "        sales_hat = np.sum(sales_function(optimal_prices, alpha, beta))\n",
    "        optimal_sales_list.append(sales_hat)\n",
    "\n",
    "    return -np.mean(optimal_sales_list)\n",
    "\n",
    "\n",
    "def estimate_bounds_zero_nelder(\n",
    "    bounds: List[float],\n",
    "    tilda_coefs_list: List[NDArray[np.float_]],\n",
    "    tilda_intercepts_list: List[NDArray[np.float_]],\n",
    "    hat_coefs_list: List[NDArray[np.float_]],\n",
    "    hat_intercepts_list: List[NDArray[np.float_]],\n",
    "    M: int,\n",
    "    K: int,\n",
    "    r_min: float,\n",
    "    r_max: float,\n",
    "    adaptive: bool = True,\n",
    ") -> Tuple[float, List[Tuple[float, float]]]:\n",
    "    # Nelder-Meadでの最適化\n",
    "    bounds_nelder = minimize(\n",
    "        cross_validation_bounds_zero,\n",
    "        bounds,\n",
    "        args=(tilda_coefs_list, tilda_intercepts_list, hat_coefs_list, hat_intercepts_list, M, K),\n",
    "        method=\"Nelder-Mead\",\n",
    "        bounds=[(r_min, r_max) for _ in range(2 * M)],\n",
    "        options={\"adaptive\": adaptive},\n",
    "    )\n",
    "\n",
    "    opt_bounds = []\n",
    "    for i in range(M):\n",
    "        opt_bounds.append((bounds_nelder.x[i], bounds_nelder.x[i + M]))\n",
    "\n",
    "    return -bounds_nelder.fun, opt_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_bounds_penalty_all_2(\n",
    "    bounds: List[float],\n",
    "    tilda_coefs_list: List[NDArray[np.float_]],\n",
    "    tilda_intercepts_list: List[NDArray[np.float_]],\n",
    "    hat_coefs_list: List[NDArray[np.float_]],\n",
    "    hat_intercepts_list: List[NDArray[np.float_]],\n",
    "    M: int,\n",
    "    K: int,\n",
    "    bounds_range: float,\n",
    ") -> float:\n",
    "    # bounds の整合性チェック\n",
    "    for i in range(M):\n",
    "        if bounds[i] > bounds[i + M]:\n",
    "            # ペナルティ計算\n",
    "            return 0.0\n",
    "    bounds_list = [(bounds[i], bounds[i + M]) for i in range(M)]\n",
    "    optimal_sales_list = []\n",
    "\n",
    "    # すでに外部でKFold分割や学習が終わっているものとして\n",
    "    # tilda_coefs_list[i], tilda_intercepts_list[i], hat_coefs_list[i], hat_intercepts_list[i]\n",
    "    # を使用して最適化と売上計算\n",
    "    for i in range(K):\n",
    "        intercepts = tilda_intercepts_list[i]\n",
    "        coefs = tilda_coefs_list[i]\n",
    "\n",
    "        # 最適化\n",
    "        initial_prices = np.full(M, 0.6)\n",
    "        result = minimize(\n",
    "            predict_objective_function,\n",
    "            initial_prices,\n",
    "            args=(intercepts, coefs, M),\n",
    "            bounds=bounds_list,\n",
    "            method=\"L-BFGS-B\",\n",
    "        )\n",
    "        optimal_prices = result.x\n",
    "\n",
    "        # hatモデルパラメータで売上計算\n",
    "        alpha = hat_intercepts_list[i]\n",
    "        beta = hat_coefs_list[i]\n",
    "\n",
    "        sales_hat = np.sum(sales_function(optimal_prices, alpha, beta))\n",
    "        optimal_sales_list.append(sales_hat)\n",
    "\n",
    "    mean_sales = np.mean(optimal_sales_list)\n",
    "    # ペナルティ計算\n",
    "    penalty = 0.0\n",
    "    for i in range(M):\n",
    "        penalty += bounds[i + M] - bounds[i]\n",
    "    print(penalty)\n",
    "\n",
    "    if penalty > M * bounds_range:\n",
    "        return 0\n",
    "    else:\n",
    "        return -mean_sales\n",
    "\n",
    "\n",
    "def estimate_bounds_penalty_nelder_all_2(\n",
    "    bounds: List[float],\n",
    "    tilda_coefs_list: List[NDArray[np.float_]],\n",
    "    tilda_intercepts_list: List[NDArray[np.float_]],\n",
    "    hat_coefs_list: List[NDArray[np.float_]],\n",
    "    hat_intercepts_list: List[NDArray[np.float_]],\n",
    "    M: int,\n",
    "    K: int,\n",
    "    r_min: float,\n",
    "    r_max: float,\n",
    "    bounds_range: float,\n",
    "    adaptive: bool = True,\n",
    ") -> Tuple[float, List[Tuple[float, float]]]:\n",
    "    # Nelder-Meadでの最適化\n",
    "    bounds_nelder = minimize(\n",
    "        cross_validation_bounds_penalty_all_2,\n",
    "        bounds,\n",
    "        args=(\n",
    "            tilda_coefs_list,\n",
    "            tilda_intercepts_list,\n",
    "            hat_coefs_list,\n",
    "            hat_intercepts_list,\n",
    "            M,\n",
    "            K,\n",
    "            bounds_range,\n",
    "        ),\n",
    "        method=\"Nelder-Mead\",\n",
    "        bounds=[(r_min, r_max) for _ in range(2 * M)],\n",
    "        options={\"adaptive\": adaptive},\n",
    "    )\n",
    "\n",
    "    opt_bounds = []\n",
    "    for i in range(M):\n",
    "        opt_bounds.append((bounds_nelder.x[i], bounds_nelder.x[i + M]))\n",
    "\n",
    "    return -bounds_nelder.fun, opt_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[(0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1)]\n",
      "[(0.531616211636092, 1.0999999999999996), (0.533192291116992, 1.0802199424599013), (0.6351129942857512, 1.0722851380623681), (0.5331125566130955, 1.0786822301600276), (0.5275215777637282, 0.993020359518922)]\n",
      "[(0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1)]\n",
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m cv_sales_list_5\u001b[38;5;241m.\u001b[39mappend(cv_sales \u001b[38;5;241m/\u001b[39m so_sales)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# EBZ\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m ebz_val, ebz_bounds \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_bounds_zero_nelder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtilda_coefs_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtilda_intercepts_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhat_coefs_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhat_intercepts_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m ebz_po_sales, ebz_po_prices \u001b[38;5;241m=\u001b[39m predict_optimize(M, X, Y, ebz_bounds)\n\u001b[0;32m     84\u001b[0m true_ebz_po_sales \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sales_function(ebz_po_prices, alpha, beta))\n",
      "Cell \u001b[1;32mIn[6], line 59\u001b[0m, in \u001b[0;36mestimate_bounds_zero_nelder\u001b[1;34m(bounds, tilda_coefs_list, tilda_intercepts_list, hat_coefs_list, hat_intercepts_list, M, K, r_min, r_max, adaptive)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_bounds_zero_nelder\u001b[39m(\n\u001b[0;32m     47\u001b[0m     bounds: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m     48\u001b[0m     tilda_coefs_list: List[NDArray[np\u001b[38;5;241m.\u001b[39mfloat_]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, List[Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]]:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Nelder-Meadでの最適化\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     bounds_nelder \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation_bounds_zero\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtilda_coefs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtilda_intercepts_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhat_coefs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhat_intercepts_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNelder-Mead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_max\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madaptive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madaptive\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     opt_bounds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:701\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    698\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback, meth)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnelder-mead\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 701\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    702\u001b[0m                                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowell\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    704\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_powell(fun, x0, args, callback, bounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:880\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[1;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    879\u001b[0m     xcc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(xcc, lower_bound, upper_bound)\n\u001b[1;32m--> 880\u001b[0m fxcc \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fxcc \u001b[38;5;241m<\u001b[39m fsim[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m    883\u001b[0m     sim[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m xcc\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:526\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[1;34m(x, *wrapper_args)\u001b[0m\n\u001b[0;32m    524\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mcross_validation_bounds_zero\u001b[1;34m(bounds, tilda_coefs_list, tilda_intercepts_list, hat_coefs_list, hat_intercepts_list, M, K)\u001b[0m\n\u001b[0;32m     24\u001b[0m coefs \u001b[38;5;241m=\u001b[39m tilda_coefs_list[i]\n\u001b[0;32m     26\u001b[0m initial_prices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(M, \u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_objective_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_prices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mintercepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m optimal_prices \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 得られた最適価格でhatパラメータに基づく売上計算\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:297\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    182\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:590\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[0;32m    589\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    592\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(fun(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\m-kum\\kaggle\\experiment1\\.venv\\lib\\site-packages\\numpy\\lib\\function_base.py:962\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(a, order, subok)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    875\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03m    Return an array copy of the given object.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m \n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 実験設定\n",
    "\n",
    "M = 5\n",
    "K = 5\n",
    "N = 500\n",
    "r_mean = 0.8\n",
    "r_std = 0.1\n",
    "r_min = 0.5\n",
    "r_max = 1.1\n",
    "delta = 0.6\n",
    "z_range = 0.3\n",
    "lb, ub, bounds, range_bounds = create_bounds(M, r_min, r_max)\n",
    "\n",
    "\n",
    "# 100回実験を行う\n",
    "so_sales_list_5 = []\n",
    "po_sales_list_5 = []\n",
    "true_po_sales_list_5 = []\n",
    "cv_sales_list_5 = []\n",
    "ebz_po_sales_list_5 = []\n",
    "true_ebz_po_sales_list_5 = []\n",
    "cv_evz_sales_list_5 = []\n",
    "ebpa2_po_sales_list_5 = []\n",
    "true_po_ebpa2_sales_list_5 = []\n",
    "cv_evpa2_sales_list_5 = []\n",
    "\n",
    "for j in range(10):\n",
    "    alpha, beta, X, Y = create_date(M, N, r_mean, r_std, delta)\n",
    "    tilda_coefs_list = []\n",
    "    tilda_intercepts_list = []\n",
    "    hat_coefs_list = []\n",
    "    hat_intercepts_list = []\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # trainで学習\n",
    "        lr_tilda = MultiOutputRegressor(LinearRegression())\n",
    "\n",
    "        # 係数、切片を取得\n",
    "        lr_tilda.fit(X_train, y_train)\n",
    "        coefs = [estimate.coef_ for estimate in lr_tilda.estimators_]\n",
    "        intercepts = [estimate.intercept_ for estimate in lr_tilda.estimators_]\n",
    "\n",
    "        tilda_coefs_list.append(coefs)\n",
    "        tilda_intercepts_list.append(intercepts)\n",
    "\n",
    "        lr_hat = MultiOutputRegressor(LinearRegression())\n",
    "        lr_hat.fit(X_test, y_test)\n",
    "\n",
    "        hat_coefs = [estimate.coef_ for estimate in lr_hat.estimators_]\n",
    "        hat_intercepts = [estimate.intercept_ for estimate in lr_hat.estimators_]\n",
    "\n",
    "        hat_coefs_list.append(hat_coefs)\n",
    "        hat_intercepts_list.append(hat_intercepts)\n",
    "\n",
    "    # SO\n",
    "    so_sales, so_prices = sales_optimize(M, alpha, beta, bounds)\n",
    "    po_sales, po_prices = predict_optimize(M, X, Y, bounds)\n",
    "    true_po_sales = np.sum(sales_function(po_prices, alpha, beta))\n",
    "    cv_sales = cross_validation(\n",
    "        tilda_coefs_list, tilda_intercepts_list, hat_coefs_list, hat_intercepts_list, M, K, bounds\n",
    "    )\n",
    "\n",
    "    so_sales_list_5.append(so_sales / so_sales)\n",
    "    po_sales_list_5.append(po_sales / so_sales)\n",
    "    true_po_sales_list_5.append(true_po_sales / so_sales)\n",
    "    cv_sales_list_5.append(cv_sales / so_sales)\n",
    "\n",
    "    # EBZ\n",
    "    ebz_val, ebz_bounds = estimate_bounds_zero_nelder(\n",
    "        range_bounds,\n",
    "        tilda_coefs_list,\n",
    "        tilda_intercepts_list,\n",
    "        hat_coefs_list,\n",
    "        hat_intercepts_list,\n",
    "        M,\n",
    "        K,\n",
    "        r_min,\n",
    "        r_max,\n",
    "    )\n",
    "    ebz_po_sales, ebz_po_prices = predict_optimize(M, X, Y, ebz_bounds)\n",
    "    true_ebz_po_sales = np.sum(sales_function(ebz_po_prices, alpha, beta))\n",
    "    cv_ebz_sales = cross_validation(\n",
    "        tilda_coefs_list,\n",
    "        tilda_intercepts_list,\n",
    "        hat_coefs_list,\n",
    "        hat_intercepts_list,\n",
    "        M,\n",
    "        K,\n",
    "        ebz_bounds,\n",
    "    )\n",
    "\n",
    "    ebz_po_sales_list_5.append(ebz_po_sales / so_sales)\n",
    "    true_ebz_po_sales_list_5.append(true_ebz_po_sales / so_sales)\n",
    "    cv_evz_sales_list_5.append(cv_ebz_sales / so_sales)\n",
    "\n",
    "    # EBPA2\n",
    "    ebpa2_val, ebpa2_bounds = estimate_bounds_penalty_nelder_all_2(\n",
    "        range_bounds,\n",
    "        tilda_coefs_list,\n",
    "        tilda_intercepts_list,\n",
    "        hat_coefs_list,\n",
    "        hat_intercepts_list,\n",
    "        M,\n",
    "        K,\n",
    "        r_min,\n",
    "        r_max,\n",
    "        z_range,\n",
    "    )\n",
    "    ebpa2_po_sales, ebpa2_po_prices = predict_optimize(M, X, Y, ebpa2_bounds)\n",
    "    true_ebpa2_po_sales = np.sum(sales_function(ebpa2_po_prices, alpha, beta))\n",
    "    cv_evpa2_sales = cross_validation(\n",
    "        tilda_coefs_list,\n",
    "        tilda_intercepts_list,\n",
    "        hat_coefs_list,\n",
    "        hat_intercepts_list,\n",
    "        M,\n",
    "        K,\n",
    "        ebpa2_bounds,\n",
    "    )\n",
    "\n",
    "    ebpa2_po_sales_list_5.append(ebpa2_po_sales / so_sales)\n",
    "    true_po_ebpa2_sales_list_5.append(true_ebpa2_po_sales / so_sales)\n",
    "    cv_evpa2_sales_list_5.append(cv_evpa2_sales / so_sales)\n",
    "\n",
    "    if j % 10 == 0:\n",
    "        print(j)\n",
    "    print(bounds)\n",
    "    print(ebz_bounds)\n",
    "    print(ebpa2_bounds)\n",
    "    print(bounds == ebpa2_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0000000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-15.620638830993943"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_validation_bounds_penalty_all_2(bounds, tilda_coefs_list, tilda_intercepts_list, hat_coefs_list, hat_intercepts_list, M, K, z_range)を実行\n",
    "\n",
    "# データを作成\n",
    "alpha, beta, X, Y = create_date(M, N, r_mean, r_std, delta)\n",
    "\n",
    "# 学習\n",
    "tilda_coefs_list = []\n",
    "tilda_intercepts_list = []\n",
    "hat_coefs_list = []\n",
    "hat_intercepts_list = []\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # trainで学習\n",
    "    lr_tilda = MultiOutputRegressor(LinearRegression())\n",
    "\n",
    "    # 係数、切片を取得\n",
    "    lr_tilda.fit(X_train, y_train)\n",
    "    coefs = [estimate.coef_ for estimate in lr_tilda.estimators_]\n",
    "    intercepts = [estimate.intercept_ for estimate in lr_tilda.estimators_]\n",
    "\n",
    "    tilda_coefs_list.append(coefs)\n",
    "    tilda_intercepts_list.append(intercepts)\n",
    "\n",
    "    lr_hat = MultiOutputRegressor(LinearRegression())\n",
    "    lr_hat.fit(X_test, y_test)\n",
    "\n",
    "    hat_coefs = [estimate.coef_ for estimate in lr_hat.estimators_]\n",
    "    hat_intercepts = [estimate.intercept_ for estimate in lr_hat.estimators_]\n",
    "\n",
    "    hat_coefs_list.append(hat_coefs)\n",
    "    hat_intercepts_list.append(hat_intercepts)\n",
    "\n",
    "cross_validation_bounds_penalty_all_2(\n",
    "    range_bounds,\n",
    "    tilda_coefs_list,\n",
    "    tilda_intercepts_list,\n",
    "    hat_coefs_list,\n",
    "    hat_intercepts_list,\n",
    "    M,\n",
    "    K,\n",
    "    0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0000000000000004\n",
      "2.9750000000000005\n",
      "2.9750000000000005\n",
      "2.9750000000000005\n",
      "2.9750000000000005\n",
      "2.9750000000000005\n",
      "2.9450000000000003\n",
      "2.9450000000000003\n",
      "2.9450000000000003\n",
      "2.9450000000000003\n",
      "2.9450000000000003\n",
      "2.9309999999999974\n",
      "2.930399999999998\n",
      "2.9214799999999967\n",
      "2.9122159999999964\n",
      "2.8910191999999957\n",
      "2.881664639999996\n",
      "2.8834017919999955\n",
      "2.877651315199996\n",
      "2.8720645759999943\n",
      "2.8359784063999935\n",
      "2.8195762470399934\n",
      "2.858312011315196\n",
      "2.8480771563110343\n",
      "2.842316587573243\n",
      "2.8344002463305684\n",
      "2.836017436839357\n",
      "2.828397580523293\n",
      "2.844689912944017\n",
      "2.8400569842384202\n",
      "2.845722941791702\n",
      "2.842128771970874\n",
      "2.835731185785878\n",
      "2.8309641251644666\n",
      "2.832144224578772\n",
      "2.8275935155166505\n",
      "2.8288367516821045\n",
      "2.6966686780185194\n",
      "2.668835545820372\n",
      "2.77546137360436\n",
      "2.767176309833276\n",
      "2.7695160593129704\n",
      "2.7616599496131644\n",
      "2.7864337090986453\n",
      "2.7831194553045107\n",
      "2.761353551602858\n",
      "2.753947411626046\n",
      "2.7465023947363214\n",
      "2.7235770900104996\n",
      "2.7119291005877084\n",
      "2.6954653680014125\n",
      "2.6807990276044666\n",
      "2.67659699529582\n",
      "2.6611602823089555\n",
      "2.6451890749035516\n",
      "2.6268243072256965\n",
      "2.606278469410815\n",
      "2.584146964800232\n",
      "2.748098722903064\n",
      "2.756025040611334\n",
      "2.6475277050457735\n",
      "2.630217616352407\n",
      "2.617073383026332\n",
      "2.601667980647408\n",
      "2.5436117820143354\n",
      "2.539650720038126\n",
      "2.539768338076823\n",
      "2.542692273154536\n",
      "2.5386374166191636\n",
      "2.5570158464726322\n",
      "2.5590116995518097\n",
      "2.616652416074613\n",
      "2.6579357622069857\n",
      "2.5599787965124037\n",
      "2.5726408953744673\n",
      "2.6100506879695917\n",
      "2.61032709128272\n",
      "2.588073983772605\n",
      "2.643669837070315\n",
      "2.5700139450622848\n",
      "2.6669664668632147\n",
      "2.5588480573947825\n",
      "2.6465298606041108\n",
      "2.57296145612616\n",
      "2.5890401227782354\n",
      "2.5398655892485458\n",
      "2.6313783876761896\n",
      "2.607980191302432\n",
      "2.59105991490208\n",
      "2.607418010721571\n",
      "2.4107116869105214\n",
      "2.5648623308292167\n",
      "2.5189471291914582\n",
      "2.5941473784920546\n",
      "2.567359818616381\n",
      "2.5652369539972906\n",
      "2.5746518713713162\n",
      "2.561218629491262\n",
      "2.5581899073129604\n",
      "2.5707457238041798\n",
      "2.4876464429885283\n",
      "2.6098185959730404\n",
      "2.5934076858135744\n",
      "2.5477142649044433\n",
      "2.5333293609500935\n",
      "2.582400331809281\n",
      "2.5278924880235634\n",
      "2.5842091449217808\n",
      "2.5654193401104606\n",
      "2.746867813331189\n",
      "2.461135105873621\n",
      "2.6032085208853006\n",
      "2.5874955687322356\n",
      "2.5509579421155344\n",
      "2.5858676369309865\n",
      "2.6105440746783692\n",
      "2.554650176716632\n",
      "2.5705847444020478\n",
      "2.5704205969001954\n",
      "2.575378489726395\n",
      "2.4313478565221023\n",
      "2.733888370300704\n",
      "2.4767289335888925\n",
      "2.6045950070994044\n",
      "2.590453350161645\n",
      "2.5575694862066145\n",
      "2.5889882115405207\n",
      "2.611197005513166\n",
      "2.560892497347602\n",
      "2.575233608264476\n",
      "2.5795479790563887\n",
      "2.5750858755128085\n",
      "2.4499204091725257\n",
      "2.722206871573267\n",
      "2.490763378532636\n",
      "2.6058428446920967\n",
      "2.5635198758885864\n",
      "2.5931153534481135\n",
      "2.5917967286891024\n",
      "2.6117846432644822\n",
      "2.5665105859154744\n",
      "2.5833005194533825\n",
      "2.579417585740662\n",
      "2.579284626264161\n",
      "2.466635706557906\n",
      "2.711693522718573\n",
      "2.503394378982006\n",
      "2.606965898525521\n",
      "2.568875226602361\n",
      "2.5955111564059354\n",
      "2.5943243941228253\n",
      "2.5715668656265604\n",
      "2.612313517240667\n",
      "2.5866778058106776\n",
      "2.5831831654692285\n",
      "2.5830635019403783\n",
      "2.4816794742047485\n",
      "2.7022315087493483\n",
      "2.5147622793864386\n",
      "2.669148703567658\n",
      "2.5379202430136214\n",
      "2.5918188292283677\n",
      "2.5934262984513454\n",
      "2.584719635416546\n",
      "2.58954002403107\n",
      "2.587107138543737\n",
      "2.558863036861694\n",
      "2.604295945183821\n",
      "2.6465314515227796\n",
      "2.5542119242899948\n",
      "2.609413840642527\n",
      "2.5772439118789556\n",
      "2.5832402156974887\n",
      "2.5849028424612888\n",
      "2.58436258323853\n",
      "2.590700392329892\n",
      "2.5797081032457543\n",
      "2.593140698431908\n",
      "2.592183836838216\n",
      "2.585839265629796\n",
      "2.5895427591282383\n",
      "2.6119081775747883\n",
      "2.6162114726720307\n",
      "2.5756666204809298\n",
      "2.595882432149091\n",
      "2.586549780914459\n",
      "2.6330409216452773\n",
      "2.566036273893287\n",
      "2.607767406459184\n",
      "2.58182243606599\n",
      "2.5925353347554676\n",
      "2.590975633693728\n",
      "2.5762757196035198\n",
      "2.5883754977541584\n",
      "2.589367669922126\n",
      "2.604991846289706\n",
      "2.580065404352246\n",
      "2.60514068411686\n",
      "2.58060546428052\n",
      "2.593677759479134\n",
      "2.5876189776991607\n",
      "2.585982497815136\n",
      "2.5920669683393918\n",
      "2.6182930612429773\n",
      "2.57387479199574\n",
      "2.600917370256225\n",
      "2.584686676194525\n",
      "2.590506381128646\n",
      "2.5909052458089654\n",
      "2.6035845787614713\n",
      "2.5835932805136297\n",
      "2.597361520460688\n",
      "2.58756760385443\n",
      "2.603987749724746\n",
      "2.584112807097154\n",
      "2.596273002185704\n",
      "2.5889170813721423\n",
      "2.613025645764405\n",
      "2.5797474200610404\n",
      "2.5956087178658023\n",
      "2.602474119927659\n",
      "2.5873547927544953\n",
      "2.5955454597023246\n",
      "2.59160127789297\n",
      "2.5642829014582853\n",
      "2.609154810791125\n",
      "2.5884567852038787\n",
      "2.594535927966514\n",
      "2.592492326655714\n",
      "2.5921307720868403\n",
      "2.6026735127961187\n",
      "2.5864553153560035\n",
      "2.602622487864364\n",
      "2.5868892592122354\n",
      "2.597412649157394\n",
      "2.59019141653993\n",
      "2.6086711097642743\n",
      "2.584085973516525\n",
      "2.600409973223226\n",
      "2.5893130698248044\n",
      "2.600546255317366\n",
      "2.5895144015738705\n",
      "2.596095206015007\n",
      "2.5922753671112755\n",
      "2.592708443770414\n",
      "2.594261805337099\n",
      "2.602350354377144\n",
      "2.5888395712091743\n",
      "2.6023064729203003\n",
      "2.589201841268445\n",
      "2.598806400538309\n",
      "2.591483664139687\n",
      "2.576308776956826\n",
      "2.5998221749194856\n",
      "2.5864464037269697\n",
      "2.5940217453916388\n",
      "2.59001937115983\n",
      "2.5906082489148794\n",
      "2.5920252993818163\n",
      "2.6097181435543266\n",
      "2.581320181946451\n",
      "2.5917340303962346\n",
      "2.59207126083325\n",
      "2.5891648882452047\n",
      "2.593497267773315\n",
      "2.5955186616859587\n",
      "2.589841434780692\n",
      "2.5949092379626264\n",
      "2.5963632776068883\n",
      "2.5952890621561213\n",
      "2.600887246834195\n",
      "2.588612530193053\n",
      "2.595275759632151\n",
      "2.597791330306472\n",
      "2.5969386082694155\n",
      "2.6107674109693737\n",
      "2.6063503266159356\n",
      "2.598865894709677\n",
      "2.5996333445430277\n",
      "2.597369330936139\n",
      "2.5973813032077127\n",
      "2.5913724244409506\n",
      "2.5944852820171276\n",
      "2.5970394614335666\n",
      "2.5924784385698256\n",
      "2.5957686882631856\n",
      "2.584809311019009\n",
      "2.599700651941897\n",
      "2.5972685004981493\n",
      "2.6123323305826798\n",
      "2.604685681802402\n",
      "2.610417380142278\n",
      "2.612211274299524\n",
      "2.615691164242868\n",
      "2.6181230382230605\n",
      "2.6138449992050647\n",
      "2.6175359762619363\n",
      "2.618522619496255\n",
      "2.6232214142869212\n",
      "2.625656966244646\n",
      "2.63049650164775\n",
      "2.6338193017627103\n",
      "2.619730065799225\n",
      "2.62046983932088\n",
      "2.6305335460831984\n",
      "2.641685154771964\n",
      "2.6302690704618166\n",
      "2.6316748302407964\n",
      "2.6362015101359297\n",
      "2.6362436398538573\n",
      "2.6463748149271353\n",
      "2.645633908816579\n",
      "2.651535664208478\n",
      "2.649177475779659\n",
      "2.6440867750649852\n",
      "2.636701246114336\n",
      "2.636202855248574\n",
      "2.6489867166361787\n",
      "2.6333015216661453\n",
      "2.661616759867549\n",
      "2.6266418774028804\n",
      "2.6284020037334126\n",
      "2.643298054260381\n",
      "2.653288933895146\n",
      "2.6471467859139395\n",
      "2.6288309325584818\n",
      "2.65380364848523\n",
      "2.6322122504461856\n",
      "2.6357439722298968\n",
      "2.625136744690688\n",
      "2.647102638767125\n",
      "2.6297043211664692\n",
      "2.628037271790403\n",
      "2.6430318899162613\n",
      "2.6290898277658052\n",
      "2.6274354196607286\n",
      "2.637318053838655\n",
      "2.6370332690116522\n",
      "2.624107419571113\n",
      "2.631635766585292\n",
      "2.636223643647698\n",
      "2.623956099214028\n",
      "2.6340355770282575\n",
      "2.6342716517070035\n",
      "2.642353429045882\n",
      "2.6277192473439666\n",
      "2.628252358598977\n",
      "2.619582616257912\n",
      "2.6332679326129957\n",
      "2.6338228011398996\n",
      "2.6111175999590115\n",
      "2.6075190960782\n",
      "2.616255685564539\n",
      "2.6218276360063735\n",
      "2.6211851637471133\n",
      "2.625388123869438\n",
      "2.62551619429927\n",
      "2.6350919596229576\n",
      "2.6190811266733016\n",
      "2.6117204442238684\n",
      "2.616622662168731\n",
      "2.6154812012065647\n",
      "2.6248588221924853\n",
      "2.6254125737947893\n",
      "2.621330385754826\n",
      "2.616630058526946\n",
      "2.615549522413568\n",
      "2.6065487974591544\n",
      "2.603800119502244\n",
      "2.601422879252266\n",
      "2.5982383739161934\n",
      "2.62531557135466\n",
      "2.6074026931500454\n",
      "2.6088736090783087\n",
      "2.6076424536114287\n",
      "2.6012085779221135\n",
      "2.6216995223397785\n",
      "2.605267590838938\n",
      "2.6135869616929113\n",
      "2.5981942116243797\n",
      "2.5920724429826167\n",
      "2.5887280678509517\n",
      "2.596756809404199\n",
      "2.5952850184601095\n",
      "2.587972913612708\n",
      "2.6123314867898113\n",
      "2.5810298426898806\n",
      "2.615599070392294\n",
      "2.596965947328065\n",
      "2.5974407209369956\n",
      "2.5966580339468024\n",
      "2.597636312560641\n",
      "2.5970199318664813\n",
      "2.606498396284049\n",
      "2.5969670251337003\n",
      "2.586379035623125\n",
      "2.599625899377121\n",
      "2.5777992199154927\n",
      "2.609929092820774\n",
      "2.611729266124192\n",
      "2.5901815701982844\n",
      "2.5982585670875418\n",
      "2.5982605864046775\n",
      "2.598316004335416\n",
      "2.5842585054419493\n",
      "2.5818683550173995\n",
      "2.597666595394366\n",
      "2.5965438416149533\n",
      "2.591048762630604\n",
      "2.589656187767246\n",
      "2.585002293396216\n",
      "2.60051844492224\n",
      "2.5866974963639935\n",
      "2.5956427682158454\n",
      "2.589765272905686\n",
      "2.58647128070999\n",
      "2.5823301732644417\n",
      "2.5959181296747706\n",
      "2.5829009384104182\n",
      "2.595259753558009\n",
      "2.595628073207026\n",
      "2.594254554332471\n",
      "2.5933628394628148\n",
      "2.590212185521581\n",
      "2.599058712258919\n",
      "2.587110756225621\n",
      "2.5937648294134354\n",
      "2.598246072565016\n",
      "2.5884297827941465\n",
      "2.5901117301917163\n",
      "2.593216864530177\n",
      "2.5882082282415766\n",
      "2.594202024760544\n",
      "2.58720663114197\n",
      "2.5874606218461693\n",
      "2.5884797117191143\n",
      "2.5911564958965654\n",
      "2.5903538320778288\n",
      "2.587579210397501\n",
      "2.5923712164102755\n",
      "2.594737410738988\n",
      "2.584371730872628\n",
      "2.5951227017174037\n",
      "2.595768245712226\n",
      "2.588490873327509\n",
      "2.5876306218070457\n",
      "2.5932163143175195\n",
      "2.594360170078117\n",
      "2.5893193408867425\n",
      "2.5869689281628268\n",
      "2.5935721383525645\n",
      "2.594245112509391\n",
      "2.5893445218376554\n",
      "2.5913352134393124\n",
      "2.589805559065447\n",
      "2.591986367808551\n",
      "2.5921494505440386\n",
      "2.59062317484776\n",
      "2.5864806755305354\n",
      "2.5938263977893734\n",
      "2.5941796088128024\n",
      "2.6032643778819926\n",
      "2.585077758447088\n",
      "2.594965075524719\n",
      "2.5901662010824387\n",
      "2.5900310906048722\n",
      "2.593040981190411\n",
      "2.5949979989903316\n",
      "2.5901925434105566\n",
      "2.5927787733829235\n",
      "2.591551747430854\n",
      "2.590564759127383\n",
      "2.5928185810389994\n",
      "2.58932925907734\n",
      "2.5900568115376594\n",
      "2.591136588827413\n",
      "2.5918589009613804\n",
      "2.5994014266917347\n",
      "2.5872263086837854\n",
      "2.5931766370582663\n",
      "2.591006194179336\n",
      "2.590351873313401\n",
      "2.5926376150088597\n",
      "2.589328700158336\n",
      "2.5931517431447175\n",
      "2.593586005277726\n",
      "2.594238355323042\n",
      "2.59079941519743\n",
      "2.5912084845262853\n",
      "2.592577066562092\n",
      "2.5926803819606796\n",
      "2.5917210426103283\n",
      "2.594508164068408\n",
      "2.590724514417272\n",
      "2.592479197335863\n",
      "2.591951945417552\n",
      "2.5904252810474837\n",
      "2.5931118966431894\n",
      "2.5847209619682348\n",
      "2.5962296427392113\n",
      "2.5975559065002125\n",
      "2.588775748356249\n",
      "2.5935780666183312\n",
      "2.5912162129105645\n",
      "2.593413291382671\n",
      "2.5913672587598358\n",
      "2.592627686181581\n",
      "2.5918570391460163\n",
      "2.5909380448474515\n",
      "2.592819688400128\n",
      "2.593784308371468\n",
      "2.5911834835104015\n",
      "2.5916530396163093\n",
      "2.5924384625202244\n",
      "2.5915526606718142\n",
      "2.592474871858303\n",
      "2.5923429155512725\n",
      "2.5920105909376105\n",
      "2.5961660811288487\n",
      "2.589884298272139\n",
      "2.591184413167698\n",
      "2.5928227741218652\n",
      "2.587385293348207\n",
      "2.59490299033056\n",
      "2.5931360786608524\n",
      "2.5915041927731073\n",
      "2.5930124196142357\n",
      "2.591614032887996\n",
      "2.5924740379764515\n",
      "2.5919495889705817\n",
      "2.591794839892315\n",
      "2.5923419191260377\n",
      "2.5932815060252645\n",
      "2.5914981868876303\n",
      "2.591381000833039\n",
      "2.5926038852650644\n",
      "2.5917516200562165\n",
      "2.59236638408799\n",
      "2.592287059606985\n",
      "2.592245589306579\n",
      "2.594885610479344\n",
      "2.59063449510322\n",
      "2.59150947882589\n",
      "2.5926257798274692\n",
      "2.5889738205165758\n",
      "2.5918665436227224\n",
      "2.594975460500483\n",
      "2.589874066514162\n",
      "2.5919872548542946\n",
      "2.591670016182941\n",
      "2.5915957842141815\n",
      "2.5918965182571214\n",
      "2.59212685257103\n",
      "2.591592486740141\n",
      "2.5911332338554445\n",
      "2.592160616335449\n",
      "2.5916674239013058\n",
      "2.5918366756645095\n",
      "2.591061641751341\n",
      "2.5921706727374927\n",
      "2.5907374980687523\n",
      "2.592323927185618\n",
      "2.5930447746470766\n",
      "2.590996037034798\n",
      "2.5911837699893616\n",
      "2.592086316408996\n",
      "2.590695686784777\n",
      "2.592336265871065\n",
      "2.5939398399694644\n",
      "2.590483932532457\n",
      "2.5916348710815713\n",
      "2.591857271180789\n",
      "2.5918988241553227\n",
      "2.591704337378798\n",
      "2.5919987237258533\n",
      "2.591653422287998\n",
      "2.5913291553210556\n",
      "2.5920358971832895\n",
      "2.5911082384704214\n",
      "2.592141573878339\n",
      "2.5926652359899487\n",
      "2.5912464168780707\n",
      "2.591706545602949\n",
      "2.591817156155275\n",
      "2.5914030728077186\n",
      "2.5919838298688047\n",
      "2.5912813479054853\n",
      "2.592037274012691\n",
      "2.5916307500285694\n",
      "2.5918232930079563\n",
      "2.593271960772001\n",
      "2.5909021367683884\n",
      "2.591952213912539\n",
      "2.5916982410316782\n",
      "2.591141765361594\n",
      "2.592157090794645\n",
      "2.5918642445370317\n",
      "2.591728323452533\n",
      "2.591344357952329\n",
      "2.5913117268011847\n",
      "2.591927271625974\n",
      "2.5922373780559846\n",
      "2.5913950610547576\n",
      "2.5913822113024407\n",
      "2.5918935870838498\n",
      "2.5921315290452225\n",
      "2.591721605420264\n",
      "2.591802823545024\n",
      "2.591341491430278\n",
      "2.592013023402981\n",
      "2.5914308963408654\n",
      "2.591946317361917\n",
      "2.5916694822163926\n",
      "2.5918002213892217\n",
      "2.5918149302641793\n",
      "2.591715744416554\n",
      "2.5927737560571034\n",
      "2.5911828796616954\n",
      "2.5913239598042574\n",
      "2.592032121146086\n",
      "2.5918134866850804\n",
      "2.591741097937415\n",
      "2.5915773037739274\n",
      "2.591874776448167\n",
      "2.592205457423825\n",
      "2.591516620510118\n",
      "2.591488214497029\n",
      "2.5915265762987962\n",
      "2.591838535466092\n",
      "2.591624482221835\n",
      "2.591776072346545\n",
      "2.591446939401868\n",
      "2.591896787247723\n",
      "2.591549500409633\n",
      "2.591958574544437\n",
      "2.591636963188127\n",
      "2.591775732659057\n",
      "2.591442041655836\n",
      "2.5915195215891265\n",
      "2.591645627218234\n",
      "2.591705226836806\n",
      "2.592282961408114\n",
      "2.5913478919236583\n"
     ]
    }
   ],
   "source": [
    "bounds_nelder = minimize(\n",
    "    cross_validation_bounds_penalty_all_2,\n",
    "    range_bounds,\n",
    "    args=(\n",
    "        tilda_coefs_list,\n",
    "        tilda_intercepts_list,\n",
    "        hat_coefs_list,\n",
    "        hat_intercepts_list,\n",
    "        M,\n",
    "        K,\n",
    "        0.7,\n",
    "    ),\n",
    "    method=\"Nelder-Mead\",\n",
    "    bounds=[(r_min, r_max) for _ in range(2 * M)],\n",
    "    options={\"adaptive\": True},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: Optimization terminated successfully.\n",
       "       success: True\n",
       "        status: 0\n",
       "           fun: -15.828216508377503\n",
       "             x: [ 5.545e-01  5.171e-01  5.104e-01  6.333e-01  5.099e-01\n",
       "                  1.083e+00  1.051e+00  1.047e+00  1.100e+00  1.036e+00]\n",
       "           nit: 342\n",
       "          nfev: 643\n",
       " final_simplex: (array([[ 5.545e-01,  5.171e-01, ...,  1.100e+00,\n",
       "                         1.036e+00],\n",
       "                       [ 5.545e-01,  5.172e-01, ...,  1.100e+00,\n",
       "                         1.036e+00],\n",
       "                       ...,\n",
       "                       [ 5.545e-01,  5.171e-01, ...,  1.100e+00,\n",
       "                         1.036e+00],\n",
       "                       [ 5.545e-01,  5.171e-01, ...,  1.100e+00,\n",
       "                         1.036e+00]]), array([-1.583e+01, -1.583e+01, -1.583e+01, -1.583e+01,\n",
       "                       -1.583e+01, -1.583e+01, -1.583e+01, -1.583e+01,\n",
       "                       -1.583e+01, -1.583e+01, -1.583e+01]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_nelder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_bounds = []\n",
    "for i in range(M):\n",
    "    opt_bounds.append((bounds_nelder.x[i], bounds_nelder.x[i + M]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5544926778107351, 1.082524489083257),\n",
       " (0.5171430836689331, 1.0508309420570794),\n",
       " (0.5104048993056337, 1.0473559680681992),\n",
       " (0.6333260729146736, 1.0999999999999996),\n",
       " (0.509904112692154, 1.0362646740204)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       " array([1.1, 1.1, 1.1, 1.1, 1.1]),\n",
       " [(0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1), (0.5, 1.1)],\n",
       " [0.5, 0.5, 0.5, 0.5, 0.5, 1.1, 1.1, 1.1, 1.1, 1.1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bounds(M, r_min, r_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M * z_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をpandasのDataFrameに格納,csvに出力\n",
    "\n",
    "df_5 = pd.DataFrame(\n",
    "    {\n",
    "        \"SO\": so_sales_list_5,\n",
    "        \"PO\": po_sales_list_5,\n",
    "        \"True PO\": true_po_sales_list_5,\n",
    "        \"CV\": cv_sales_list_5,\n",
    "        \"EBZ\": ebz_po_sales_list_5,\n",
    "        \"True EBZ\": true_ebz_po_sales_list_5,\n",
    "        \"CV EBZ\": cv_evz_sales_list_5,\n",
    "        \"EBPA2\": ebpa2_po_sales_list_5,\n",
    "        \"True EBPA2\": true_po_ebpa2_sales_list_5,\n",
    "        \"CV EBPA2\": cv_evpa2_sales_list_5,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO</th>\n",
       "      <th>PO</th>\n",
       "      <th>True PO</th>\n",
       "      <th>CV</th>\n",
       "      <th>EBZ</th>\n",
       "      <th>True EBZ</th>\n",
       "      <th>CV EBZ</th>\n",
       "      <th>EBPA2</th>\n",
       "      <th>True EBPA2</th>\n",
       "      <th>CV EBPA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.037010</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.947298</td>\n",
       "      <td>1.037010</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.947298</td>\n",
       "      <td>1.037010</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.947298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.092403</td>\n",
       "      <td>0.971755</td>\n",
       "      <td>0.981174</td>\n",
       "      <td>1.071692</td>\n",
       "      <td>0.983479</td>\n",
       "      <td>1.085859</td>\n",
       "      <td>1.092403</td>\n",
       "      <td>0.971755</td>\n",
       "      <td>0.981174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.137455</td>\n",
       "      <td>0.964199</td>\n",
       "      <td>1.090756</td>\n",
       "      <td>1.120907</td>\n",
       "      <td>0.976375</td>\n",
       "      <td>1.131002</td>\n",
       "      <td>1.137455</td>\n",
       "      <td>0.964199</td>\n",
       "      <td>1.090756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909572</td>\n",
       "      <td>0.976503</td>\n",
       "      <td>0.897435</td>\n",
       "      <td>0.908857</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.898524</td>\n",
       "      <td>0.909572</td>\n",
       "      <td>0.976503</td>\n",
       "      <td>0.897435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.023513</td>\n",
       "      <td>0.955641</td>\n",
       "      <td>0.840187</td>\n",
       "      <td>0.990941</td>\n",
       "      <td>0.973136</td>\n",
       "      <td>0.943181</td>\n",
       "      <td>1.023513</td>\n",
       "      <td>0.955641</td>\n",
       "      <td>0.840187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.026389</td>\n",
       "      <td>0.963947</td>\n",
       "      <td>0.949737</td>\n",
       "      <td>1.022109</td>\n",
       "      <td>0.971386</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>1.026389</td>\n",
       "      <td>0.963947</td>\n",
       "      <td>0.949737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044824</td>\n",
       "      <td>0.971647</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>1.034504</td>\n",
       "      <td>0.969167</td>\n",
       "      <td>1.007459</td>\n",
       "      <td>1.044824</td>\n",
       "      <td>0.971647</td>\n",
       "      <td>0.980350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926404</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.874802</td>\n",
       "      <td>0.919808</td>\n",
       "      <td>0.986595</td>\n",
       "      <td>0.879562</td>\n",
       "      <td>0.926404</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>0.874802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.983120</td>\n",
       "      <td>0.816138</td>\n",
       "      <td>0.972863</td>\n",
       "      <td>0.989533</td>\n",
       "      <td>0.864917</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.983120</td>\n",
       "      <td>0.816138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937034</td>\n",
       "      <td>0.949249</td>\n",
       "      <td>0.883051</td>\n",
       "      <td>0.935256</td>\n",
       "      <td>0.922520</td>\n",
       "      <td>0.897084</td>\n",
       "      <td>0.937034</td>\n",
       "      <td>0.949249</td>\n",
       "      <td>0.883051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SO        PO   True PO        CV       EBZ  True EBZ    CV EBZ     EBPA2  \\\n",
       "0  1.0  1.037010  0.988306  0.947298  1.037010  0.988306  0.947298  1.037010   \n",
       "1  1.0  1.092403  0.971755  0.981174  1.071692  0.983479  1.085859  1.092403   \n",
       "2  1.0  1.137455  0.964199  1.090756  1.120907  0.976375  1.131002  1.137455   \n",
       "3  1.0  0.909572  0.976503  0.897435  0.908857  0.974286  0.898524  0.909572   \n",
       "4  1.0  1.023513  0.955641  0.840187  0.990941  0.973136  0.943181  1.023513   \n",
       "5  1.0  1.026389  0.963947  0.949737  1.022109  0.971386  0.983081  1.026389   \n",
       "6  1.0  1.044824  0.971647  0.980350  1.034504  0.969167  1.007459  1.044824   \n",
       "7  1.0  0.926404  0.998428  0.874802  0.919808  0.986595  0.879562  0.926404   \n",
       "8  1.0  0.983081  0.983120  0.816138  0.972863  0.989533  0.864917  0.983081   \n",
       "9  1.0  0.937034  0.949249  0.883051  0.935256  0.922520  0.897084  0.937034   \n",
       "\n",
       "   True EBPA2  CV EBPA2  \n",
       "0    0.988306  0.947298  \n",
       "1    0.971755  0.981174  \n",
       "2    0.964199  1.090756  \n",
       "3    0.976503  0.897435  \n",
       "4    0.955641  0.840187  \n",
       "5    0.963947  0.949737  \n",
       "6    0.971647  0.980350  \n",
       "7    0.998428  0.874802  \n",
       "8    0.983120  0.816138  \n",
       "9    0.949249  0.883051  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5_mean = df_5.mean()\n",
    "df_5_std = df_5.std()\n",
    "df_5_error = df_5_std / np.sqrt(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 平均0.8, 分散0.1の正規分布に従う乱数を生成１０００個作成\n",
    "r_mean = 0.8\n",
    "r_std = 0.1\n",
    "r = np.random.normal(r_mean, r_std, 100000)\n",
    "\n",
    "# ヒストグラムを作成\n",
    "plt.hist(r, bins=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31622776601683794"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_true = [\"True PO\", \"True EBZ\", \"True EBPA2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(label_true, df_5_mean[label_true], capsize=3)\n",
    "\n",
    "# 反転\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
